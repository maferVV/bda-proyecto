volumes:
  # metadata_data: {}
  middle_var: {}
  historical_var: {}
  broker_var: {}
  coordinator_var: {}
  router_var: {}
  druid_shared: {}

services:
  spark:
    build:
      context: ./app_spark  # Specify the context for the build
    container_name: spark
    environment:
      - SPARK_MODE=master
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./app_spark/:/app/ 
      - druid_shared:/app/druid_shared  # Mount the druid_shared volume

  # Spark Worker
  worker:
    image: apache/spark:3.5.1
    container_name: worker
    depends_on:
      - spark
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark:7077
    ports:
      - "8084:8084"
    volumes:
      - ./app_spark/:/app/ 
      - druid_shared:/app/druid_shared  # Mount the druid_shared volume
