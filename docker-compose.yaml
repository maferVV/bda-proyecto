volumes:
  # metadata_data: {}
  middle_var: {}
  historical_var: {}
  broker_var: {}
  coordinator_var: {}
  router_var: {}
  druid_shared: {}

services:

  # Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 22181:2181

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    restart: unless-stopped
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
  
  spark-master:
    build: ./app_spark
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - "7077:7077"
      - "8080:8080"
    #volumes:
      #- ./app_spark:/app/etl_scripts
      #- ./data:/app/data
      #- druid_shared:/opt/shared  # shared volume compas??
    #working_dir: /app

  # Spark Worker
  spark-worker:
    build: ./app_spark
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077    
    ports:
      - "8084:8084"
    #command: ["spark-submit", "--master", "spark://spark-master:7077", "/app/scripts/etl_script.py"]
    command: ["spark-submit", "--master", "spark://spark-master:7077", "/app/etl_scripts/hello_world.py"]

  # Database for druid
  postgres:
    container_name: postgres
    image: postgres:latest
    restart: unless-stopped
    ports:
      - 5432:5432
    environment:
      - POSTGRES_PASSWORD=FoolishPassword
      - POSTGRES_USER=druid
      - POSTGRES_DB=druid


  # Druid Cordinator
  coordinator:
    image: apache/druid:33.0.0
    container_name: coordinator
    restart: unless-stopped
    volumes:
      - druid_shared:/opt/shared
      - coordinator_var:/opt/druid/var
    ports:
      - "8081:8081"
    command:
      - coordinator
    depends_on:
      - zookeeper
      - postgres
    env_file:
      - ./app_druid/environment.env

  # Druid Broker
  broker:
    image: apache/druid:33.0.0
    container_name: broker
    restart: unless-stopped
    volumes:
      - broker_var:/opt/druid/var
    ports:
      - "8082:8082"
    command:
      - broker
    depends_on: 
      - zookeeper
      - postgres
      - coordinator
    env_file:
       - ./app_druid/environment.env

  # Druid Historical
  historical:
    image: apache/druid:33.0.0
    container_name: historical
    restart: unless-stopped
    volumes:
      - druid_shared:/opt/shared
      - historical_var:/opt/druid/var
    ports:
      - "8083:8083"
    command:
      - historical
    depends_on: 
      - zookeeper
      - postgres
      - coordinator
    env_file:
      - ./app_druid/environment.env

  # Druid middlemanager
  middlemanager:
    image: apache/druid:33.0.0
    container_name: middlemanager
    volumes:
      - druid_shared:/opt/shared
      - middle_var:/opt/druid/var
    ports:
      - "8091:8091"
      - "8100-8105:8100-8105"
    command:
      - middleManager
    depends_on: 
      - zookeeper
      - postgres
      - coordinator
    env_file:
      - ./app_druid/environment.env
  
  # Druid router
  router:
    image: apache/druid:33.0.0
    container_name: router
    restart: unless-stopped
    volumes:
      - router_var:/opt/druid/var
    ports:
      - "8888:8888"
    command:
      - router
    depends_on: 
      - zookeeper
      - postgres
      - coordinator
    env_file:
      - ./app_druid/environment.env

  # Superset need to change the password and username on production
  superset:
    build: 
      context: ./app_superset
      dockerfile: ./Dockerfile
    container_name: superset
    restart: unless-stopped
    ports:
      - 8088:8088
    environment:
      - SUPERSET_SECRET_KEY=EIxAG2O3Mi9DaOsAXgSDRrpe/c4/LiuEBi6xBaEf5FcYQ0s8XdkqlOIK
    command: >
      /bin/sh -c "
        superset db upgrade &&
        superset fab create-admin --username admin --firstname Admin --lastname User --email admin@example.com --password admin &&
        superset init &&
        superset run -h 0.0.0.0 -p 8088"

  # Airflow sequency need change to celery on product
  airflow:
    build: 
      context: ./app_airflow
      dockerfile: ./Dockerfile
    container_name: airflow
    restart: unless-stopped
    volumes:
      - ./app_airflow/app/:/airflow/
    environment:
      - AIRFLOW_HOME=/airflow
      - AIRFLOW_UID=50000
      - AIRFLOW__API_AUTH__JWT_SECRET=R29rGMav62+uPLzRhcpIYo607eAjM0Xm5cc4RNmJ6AM=
      - AIRFLOW__WEBSERVER__WEB_SERVER_PASSWORD=admin
      - AIRFLOW__WEBSERVER__WEB_SERVER_USERNAME=admin
      - AIRFLOW__WEBSERVER__AUTHENTICATE=True
      - AIRFLOW__WEBSERVER__AUTH_BACKEND=airflow.www.security.auth_backend
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    ports:
      - 3000:8080
    command: airflow standalone
  
  # Redis for Airflow
  redis:
    image: redis
    restart: unless-stopped
    volumes:
      - ./a-redis:/data
